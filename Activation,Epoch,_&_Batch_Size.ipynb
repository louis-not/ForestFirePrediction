{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "R7HOqN9S9pCg"
   },
   "outputs": [],
   "source": [
    "#load library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow \n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lTtOIIEA94R_"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('/content/df_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "71jFQawT-g4K",
    "outputId": "9d7c39c9-9d18-47c1-9a75-7ce6158a7f40"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>label</th>\n",
       "      <th>damage_category</th>\n",
       "      <th>day_mon</th>\n",
       "      <th>day_sat</th>\n",
       "      <th>day_sun</th>\n",
       "      <th>day_thu</th>\n",
       "      <th>day_tue</th>\n",
       "      <th>day_wed</th>\n",
       "      <th>month_aug</th>\n",
       "      <th>month_dec</th>\n",
       "      <th>month_feb</th>\n",
       "      <th>month_jan</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4.468204</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>1.808289</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No damage</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4.517431</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>2.041220</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No damage</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4.517431</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>2.041220</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No damage</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4.529368</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No damage</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4.503137</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>2.360854</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No damage</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4.414010</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.064711</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4.414010</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.064711</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4.414010</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.064711</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.558079</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>2.509599</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No damage</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4.388257</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>0.741937</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No damage</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>510 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     X  Y      FFMC    DMC  ...  month_may  month_nov  month_oct  month_sep\n",
       "0    7  5  4.468204   26.2  ...          0          0          0          0\n",
       "1    7  4  4.517431   35.4  ...          0          0          1          0\n",
       "2    7  4  4.517431   43.7  ...          0          0          1          0\n",
       "3    8  6  4.529368   33.3  ...          0          0          0          0\n",
       "4    8  6  4.503137   51.3  ...          0          0          0          0\n",
       "..  .. ..       ...    ...  ...        ...        ...        ...        ...\n",
       "505  4  3  4.414010   56.7  ...          0          0          0          0\n",
       "506  2  4  4.414010   56.7  ...          0          0          0          0\n",
       "507  7  4  4.414010   56.7  ...          0          0          0          0\n",
       "508  1  4  4.558079  146.0  ...          0          0          0          0\n",
       "509  6  3  4.388257    3.0  ...          0          1          0          0\n",
       "\n",
       "[510 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "id": "5Y9vO49OX2lb",
    "outputId": "f02dbc7f-6cef-47d9-b2bc-22b61af3452b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>label</th>\n",
       "      <th>day_mon</th>\n",
       "      <th>day_sat</th>\n",
       "      <th>day_sun</th>\n",
       "      <th>day_thu</th>\n",
       "      <th>day_tue</th>\n",
       "      <th>day_wed</th>\n",
       "      <th>month_aug</th>\n",
       "      <th>month_dec</th>\n",
       "      <th>month_feb</th>\n",
       "      <th>month_jan</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.680392</td>\n",
       "      <td>4.294118</td>\n",
       "      <td>4.522609</td>\n",
       "      <td>111.837647</td>\n",
       "      <td>550.470392</td>\n",
       "      <td>2.228457</td>\n",
       "      <td>18.951569</td>\n",
       "      <td>44.029412</td>\n",
       "      <td>4.017255</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.527451</td>\n",
       "      <td>0.143137</td>\n",
       "      <td>0.158824</td>\n",
       "      <td>0.182353</td>\n",
       "      <td>0.119608</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.358824</td>\n",
       "      <td>0.017647</td>\n",
       "      <td>0.037255</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.103922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.320534</td>\n",
       "      <td>1.234636</td>\n",
       "      <td>0.034979</td>\n",
       "      <td>63.853719</td>\n",
       "      <td>246.630662</td>\n",
       "      <td>0.428759</td>\n",
       "      <td>5.789930</td>\n",
       "      <td>15.968323</td>\n",
       "      <td>1.788793</td>\n",
       "      <td>0.124381</td>\n",
       "      <td>0.499736</td>\n",
       "      <td>0.350557</td>\n",
       "      <td>0.365870</td>\n",
       "      <td>0.386514</td>\n",
       "      <td>0.324821</td>\n",
       "      <td>0.331599</td>\n",
       "      <td>0.307989</td>\n",
       "      <td>0.480126</td>\n",
       "      <td>0.131794</td>\n",
       "      <td>0.189572</td>\n",
       "      <td>0.044281</td>\n",
       "      <td>0.242742</td>\n",
       "      <td>0.174494</td>\n",
       "      <td>0.305458</td>\n",
       "      <td>0.062561</td>\n",
       "      <td>0.044281</td>\n",
       "      <td>0.169124</td>\n",
       "      <td>0.471867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.332048</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.741937</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.514151</td>\n",
       "      <td>73.250000</td>\n",
       "      <td>442.300000</td>\n",
       "      <td>2.041220</td>\n",
       "      <td>15.625000</td>\n",
       "      <td>32.250000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.528829</td>\n",
       "      <td>108.400000</td>\n",
       "      <td>664.200000</td>\n",
       "      <td>2.240710</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.542230</td>\n",
       "      <td>142.400000</td>\n",
       "      <td>714.200000</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.576771</td>\n",
       "      <td>291.300000</td>\n",
       "      <td>860.600000</td>\n",
       "      <td>4.044804</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                X           Y        FFMC  ...   month_nov   month_oct   month_sep\n",
       "count  510.000000  510.000000  510.000000  ...  510.000000  510.000000  510.000000\n",
       "mean     4.680392    4.294118    4.522609  ...    0.001961    0.029412    0.333333\n",
       "std      2.320534    1.234636    0.034979  ...    0.044281    0.169124    0.471867\n",
       "min      1.000000    2.000000    4.332048  ...    0.000000    0.000000    0.000000\n",
       "25%      3.000000    4.000000    4.514151  ...    0.000000    0.000000    0.000000\n",
       "50%      4.000000    4.000000    4.528829  ...    0.000000    0.000000    0.000000\n",
       "75%      7.000000    5.000000    4.542230  ...    0.000000    0.000000    1.000000\n",
       "max      9.000000    9.000000    4.576771  ...    1.000000    1.000000    1.000000\n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Sg-jKIMAYI39"
   },
   "outputs": [],
   "source": [
    "# def remove_outlier_iqr(df):\n",
    "#   Q1= df.quantile(0.25)\n",
    "#   Q3= df.quantile(0.75)\n",
    "#   IQR =Q3-Q1\n",
    "#   df_final = df[~((df<(Q1-1.5*IQR))|(df>(Q3+1.5*IQR)))]\n",
    "#   return df_final\n",
    "# df_removed_outlier = remove_outlier_iqr(df[['FFMC','DMC','RH']])\n",
    "# df = df[df_removed_outlier['FFMC'].notna()]\n",
    "# df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "id": "r2GtBkucdBVk",
    "outputId": "9e68c509-1161-4ba4-c41d-7317bcb0f528"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>label</th>\n",
       "      <th>day_mon</th>\n",
       "      <th>day_sat</th>\n",
       "      <th>day_sun</th>\n",
       "      <th>day_thu</th>\n",
       "      <th>day_tue</th>\n",
       "      <th>day_wed</th>\n",
       "      <th>month_aug</th>\n",
       "      <th>month_dec</th>\n",
       "      <th>month_feb</th>\n",
       "      <th>month_jan</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.680392</td>\n",
       "      <td>4.294118</td>\n",
       "      <td>4.522609</td>\n",
       "      <td>111.837647</td>\n",
       "      <td>550.470392</td>\n",
       "      <td>2.228457</td>\n",
       "      <td>18.951569</td>\n",
       "      <td>44.029412</td>\n",
       "      <td>4.017255</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.527451</td>\n",
       "      <td>0.143137</td>\n",
       "      <td>0.158824</td>\n",
       "      <td>0.182353</td>\n",
       "      <td>0.119608</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.358824</td>\n",
       "      <td>0.017647</td>\n",
       "      <td>0.037255</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.103922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.320534</td>\n",
       "      <td>1.234636</td>\n",
       "      <td>0.034979</td>\n",
       "      <td>63.853719</td>\n",
       "      <td>246.630662</td>\n",
       "      <td>0.428759</td>\n",
       "      <td>5.789930</td>\n",
       "      <td>15.968323</td>\n",
       "      <td>1.788793</td>\n",
       "      <td>0.124381</td>\n",
       "      <td>0.499736</td>\n",
       "      <td>0.350557</td>\n",
       "      <td>0.365870</td>\n",
       "      <td>0.386514</td>\n",
       "      <td>0.324821</td>\n",
       "      <td>0.331599</td>\n",
       "      <td>0.307989</td>\n",
       "      <td>0.480126</td>\n",
       "      <td>0.131794</td>\n",
       "      <td>0.189572</td>\n",
       "      <td>0.044281</td>\n",
       "      <td>0.242742</td>\n",
       "      <td>0.174494</td>\n",
       "      <td>0.305458</td>\n",
       "      <td>0.062561</td>\n",
       "      <td>0.044281</td>\n",
       "      <td>0.169124</td>\n",
       "      <td>0.471867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.332048</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.741937</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.514151</td>\n",
       "      <td>73.250000</td>\n",
       "      <td>442.300000</td>\n",
       "      <td>2.041220</td>\n",
       "      <td>15.625000</td>\n",
       "      <td>32.250000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.528829</td>\n",
       "      <td>108.400000</td>\n",
       "      <td>664.200000</td>\n",
       "      <td>2.240710</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.542230</td>\n",
       "      <td>142.400000</td>\n",
       "      <td>714.200000</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.576771</td>\n",
       "      <td>291.300000</td>\n",
       "      <td>860.600000</td>\n",
       "      <td>4.044804</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                X           Y        FFMC  ...   month_nov   month_oct   month_sep\n",
       "count  510.000000  510.000000  510.000000  ...  510.000000  510.000000  510.000000\n",
       "mean     4.680392    4.294118    4.522609  ...    0.001961    0.029412    0.333333\n",
       "std      2.320534    1.234636    0.034979  ...    0.044281    0.169124    0.471867\n",
       "min      1.000000    2.000000    4.332048  ...    0.000000    0.000000    0.000000\n",
       "25%      3.000000    4.000000    4.514151  ...    0.000000    0.000000    0.000000\n",
       "50%      4.000000    4.000000    4.528829  ...    0.000000    0.000000    0.000000\n",
       "75%      7.000000    5.000000    4.542230  ...    0.000000    0.000000    1.000000\n",
       "max      9.000000    9.000000    4.576771  ...    1.000000    1.000000    1.000000\n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xjYSb8_zDbgv"
   },
   "outputs": [],
   "source": [
    "df.drop('damage_category',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fQFzteBDDP7W",
    "outputId": "5398e032-72cd-4703-81ff-485c64eb3668"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# Import library for VIF\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def calc_vif(X):\n",
    "\n",
    "    # Calculating VIF\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "    return(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "id": "pLb0N3KwDn2c",
    "outputId": "61e0b557-92c7-461c-a453-09e064b80518"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X</td>\n",
       "      <td>7.623238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y</td>\n",
       "      <td>15.864570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DMC</td>\n",
       "      <td>6.486783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RH</td>\n",
       "      <td>8.786094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wind</td>\n",
       "      <td>6.042955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rain</td>\n",
       "      <td>1.101271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>day_mon</td>\n",
       "      <td>1.765099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>day_sat</td>\n",
       "      <td>1.831676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>day_sun</td>\n",
       "      <td>1.984669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>day_thu</td>\n",
       "      <td>1.620317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>day_tue</td>\n",
       "      <td>1.641650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>day_wed</td>\n",
       "      <td>1.545382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>month_dec</td>\n",
       "      <td>1.262665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>month_feb</td>\n",
       "      <td>1.337328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>month_jan</td>\n",
       "      <td>1.049520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>month_jul</td>\n",
       "      <td>1.123718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>month_jun</td>\n",
       "      <td>1.098223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>month_mar</td>\n",
       "      <td>1.642842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>month_may</td>\n",
       "      <td>1.046574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>month_nov</td>\n",
       "      <td>1.030269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>month_oct</td>\n",
       "      <td>1.144054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    variables        VIF\n",
       "0           X   7.623238\n",
       "1           Y  15.864570\n",
       "2         DMC   6.486783\n",
       "3          RH   8.786094\n",
       "4        wind   6.042955\n",
       "5        rain   1.101271\n",
       "6     day_mon   1.765099\n",
       "7     day_sat   1.831676\n",
       "8     day_sun   1.984669\n",
       "9     day_thu   1.620317\n",
       "10    day_tue   1.641650\n",
       "11    day_wed   1.545382\n",
       "12  month_dec   1.262665\n",
       "13  month_feb   1.337328\n",
       "14  month_jan   1.049520\n",
       "15  month_jul   1.123718\n",
       "16  month_jun   1.098223\n",
       "17  month_mar   1.642842\n",
       "18  month_may   1.046574\n",
       "19  month_nov   1.030269\n",
       "20  month_oct   1.144054"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_vif(df.drop(['label','FFMC','DC','ISI','temp','month_sep','month_aug'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "tqdb2_5AhVsL"
   },
   "outputs": [],
   "source": [
    "df.drop(['FFMC','DC','ISI','temp','month_sep','month_aug'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "sr6MU2aeFlEd",
    "outputId": "0f3c4959-e0fc-4175-ca75-2a66ae44e7b6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>DMC</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>label</th>\n",
       "      <th>day_mon</th>\n",
       "      <th>day_sat</th>\n",
       "      <th>day_sun</th>\n",
       "      <th>day_thu</th>\n",
       "      <th>day_tue</th>\n",
       "      <th>day_wed</th>\n",
       "      <th>month_dec</th>\n",
       "      <th>month_feb</th>\n",
       "      <th>month_jan</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>26.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>35.4</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>43.7</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>33.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>51.3</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>56.7</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>56.7</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>56.7</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>510 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     X  Y    DMC  RH  ...  month_mar  month_may  month_nov  month_oct\n",
       "0    7  5   26.2  51  ...          1          0          0          0\n",
       "1    7  4   35.4  33  ...          0          0          0          1\n",
       "2    7  4   43.7  33  ...          0          0          0          1\n",
       "3    8  6   33.3  97  ...          1          0          0          0\n",
       "4    8  6   51.3  99  ...          1          0          0          0\n",
       "..  .. ..    ...  ..  ...        ...        ...        ...        ...\n",
       "505  4  3   56.7  32  ...          0          0          0          0\n",
       "506  2  4   56.7  71  ...          0          0          0          0\n",
       "507  7  4   56.7  70  ...          0          0          0          0\n",
       "508  1  4  146.0  42  ...          0          0          0          0\n",
       "509  6  3    3.0  31  ...          0          0          1          0\n",
       "\n",
       "[510 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3te3gI34iUmw"
   },
   "outputs": [],
   "source": [
    "features = df.drop(columns='label')\n",
    "labels = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.8, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "OEr1f6b4XWDp"
   },
   "outputs": [],
   "source": [
    "predictor_vars = X_train.columns\n",
    "\n",
    "for col in predictor_vars:\n",
    "    # Calculating variable mean and std from training data\n",
    "    col_mean = X_train[col].mean()\n",
    "    col_std = X_train[col].std()\n",
    "    if col_std == 0:\n",
    "        col_std = 1e-20\n",
    "    X_train[col] = (X_train[col] - col_mean) / col_std\n",
    "    X_test[col] = (X_test[col] - col_mean) / col_std    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QsxuvIt9lZEd"
   },
   "outputs": [],
   "source": [
    "X_train=X_train.to_numpy()\n",
    "X_test=X_test.to_numpy()\n",
    "y_train=y_train.to_numpy()\n",
    "y_test=y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "MGUV_gt6HX_e"
   },
   "outputs": [],
   "source": [
    "# define the keras sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HNyVxniM_x3S"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(50, activation='relu')) # input layer + 1st hidden layer\n",
    "model.add(Dense(30, activation='relu')) # 2nd hidden layer \n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid')) # output layerm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uoGTVbPOdt5t",
    "outputId": "1f6bfbfc-6900-4041-97e9-083df0620018"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5784313678741455\n",
      "0.5024510025978088\n"
     ]
    }
   ],
   "source": [
    "  # compile model\n",
    "  optimizer = SGD(lr=0.01, momentum=0.9)\n",
    "  model.compile(loss='hinge', optimizer=optimizer, metrics=['accuracy'])\n",
    "  _, train_acc = model.evaluate(X_train,y_train, verbose=0)\n",
    "  _, valid_acc = model.evaluate(X_test,y_test, verbose=0)\n",
    "  print(train_acc)\n",
    "  print(valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AOwBCz5UTzhL",
    "outputId": "5ae94b5b-e020-4233-9f8d-875b7408b12f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.647059 using {'neurons': 5}\n",
      "0.627451 (0.049990) with: {'neurons': 1}\n",
      "0.647059 (0.072044) with: {'neurons': 5}\n",
      "0.647059 (0.072044) with: {'neurons': 10}\n",
      "0.637255 (0.060435) with: {'neurons': 15}\n",
      "0.647059 (0.072044) with: {'neurons': 20}\n",
      "0.637255 (0.060435) with: {'neurons': 25}\n",
      "0.647059 (0.072044) with: {'neurons': 30}\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(neurons=1):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(neurons, input_dim=21, kernel_initializer='uniform', activation='softmax', kernel_constraint=maxnorm(4)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "neurons = [1, 5, 10, 15, 20, 25, 30]\n",
    "param_grid = dict(neurons=neurons)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train,y_train, validation_data=(X_test,y_test))\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AfVLtXHnny0W",
    "outputId": "b536747d-31fc-4b2d-937e-55b1095b8af8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.647059 using {'activation': 'softmax'}\n",
      "0.647059 (0.041595) with: {'activation': 'softmax'}\n",
      "0.637255 (0.036683) with: {'activation': 'softplus'}\n",
      "0.607843 (0.036683) with: {'activation': 'softsign'}\n",
      "0.617647 (0.041595) with: {'activation': 'relu'}\n",
      "0.607843 (0.036683) with: {'activation': 'tanh'}\n",
      "0.637255 (0.060435) with: {'activation': 'sigmoid'}\n",
      "0.647059 (0.072044) with: {'activation': 'hard_sigmoid'}\n",
      "0.617647 (0.024015) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(activation='relu'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(10, input_dim=21, kernel_initializer='uniform', activation=activation))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train,y_train, validation_data=(X_test,y_test))\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G8YK2gQ063Y2",
    "outputId": "6acab08c-1de8-464a-8463-5c7ae3593d8e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.676471 using {'optimizer': 'Adamax'}\n",
      "0.637255 (0.055459) with: {'optimizer': 'SGD'}\n",
      "0.637255 (0.084337) with: {'optimizer': 'RMSprop'}\n",
      "0.490196 (0.113489) with: {'optimizer': 'Adagrad'}\n",
      "0.441176 (0.149971) with: {'optimizer': 'Adadelta'}\n",
      "0.647059 (0.086586) with: {'optimizer': 'Adam'}\n",
      "0.676471 (0.024015) with: {'optimizer': 'Adamax'}\n",
      "0.627451 (0.073366) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer='adam'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(10, input_dim=21, activation='softmax'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\treturn model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train,y_train, validation_data=(X_test,y_test))\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QFyqH3-5pT9v",
    "outputId": "066e2f56-04cd-4fd1-f506-5c4f42b16ca1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.647059 using {'learn_rate': 0.1, 'momentum': 0.4}\n",
      "0.627451 (0.049990) with: {'learn_rate': 0.001, 'momentum': 0.0}\n",
      "0.627451 (0.049990) with: {'learn_rate': 0.001, 'momentum': 0.2}\n",
      "0.627451 (0.049990) with: {'learn_rate': 0.001, 'momentum': 0.4}\n",
      "0.627451 (0.049990) with: {'learn_rate': 0.001, 'momentum': 0.6}\n",
      "0.627451 (0.049990) with: {'learn_rate': 0.001, 'momentum': 0.8}\n",
      "0.627451 (0.049990) with: {'learn_rate': 0.001, 'momentum': 0.9}\n",
      "0.627451 (0.049990) with: {'learn_rate': 0.01, 'momentum': 0.0}\n",
      "0.627451 (0.049990) with: {'learn_rate': 0.01, 'momentum': 0.2}\n",
      "0.627451 (0.049990) with: {'learn_rate': 0.01, 'momentum': 0.4}\n",
      "0.627451 (0.049990) with: {'learn_rate': 0.01, 'momentum': 0.6}\n",
      "0.627451 (0.049990) with: {'learn_rate': 0.01, 'momentum': 0.8}\n",
      "0.627451 (0.049990) with: {'learn_rate': 0.01, 'momentum': 0.9}\n",
      "0.627451 (0.049990) with: {'learn_rate': 0.1, 'momentum': 0.0}\n",
      "0.637255 (0.060435) with: {'learn_rate': 0.1, 'momentum': 0.2}\n",
      "0.647059 (0.063537) with: {'learn_rate': 0.1, 'momentum': 0.4}\n",
      "0.647059 (0.041595) with: {'learn_rate': 0.1, 'momentum': 0.6}\n",
      "0.607843 (0.036683) with: {'learn_rate': 0.1, 'momentum': 0.8}\n",
      "0.647059 (0.063537) with: {'learn_rate': 0.1, 'momentum': 0.9}\n",
      "0.647059 (0.024015) with: {'learn_rate': 0.2, 'momentum': 0.0}\n",
      "0.627451 (0.013865) with: {'learn_rate': 0.2, 'momentum': 0.2}\n",
      "0.578431 (0.013865) with: {'learn_rate': 0.2, 'momentum': 0.4}\n",
      "0.558824 (0.063537) with: {'learn_rate': 0.2, 'momentum': 0.6}\n",
      "0.588235 (0.041595) with: {'learn_rate': 0.2, 'momentum': 0.8}\n",
      "0.578431 (0.090918) with: {'learn_rate': 0.2, 'momentum': 0.9}\n",
      "0.627451 (0.013865) with: {'learn_rate': 0.3, 'momentum': 0.0}\n",
      "0.607843 (0.036683) with: {'learn_rate': 0.3, 'momentum': 0.2}\n",
      "0.588235 (0.083189) with: {'learn_rate': 0.3, 'momentum': 0.4}\n",
      "0.617647 (0.048029) with: {'learn_rate': 0.3, 'momentum': 0.6}\n",
      "0.568627 (0.027730) with: {'learn_rate': 0.3, 'momentum': 0.8}\n",
      "0.578431 (0.036683) with: {'learn_rate': 0.3, 'momentum': 0.9}\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(learn_rate=0.01, momentum=0):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(10, input_dim=21, kernel_initializer='uniform', activation='softmax', kernel_constraint=maxnorm(4)))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\toptimizer = SGD(lr=learn_rate, momentum=momentum)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\treturn model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "\n",
    "param_grid = dict(learn_rate=learn_rate, momentum=momentum)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train,y_train, validation_data=(X_test,y_test))\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "1yjV8_wMsvtI"
   },
   "outputs": [],
   "source": [
    "# define the keras sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "hVLWgAih_5jO"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(10, input_dim=21, kernel_initializer='uniform', activation='softmax', kernel_constraint=maxnorm(4)))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "9h7FYQX7s80e"
   },
   "outputs": [],
   "source": [
    "# compile model\n",
    "optimizer = SGD(learning_rate=0.1, momentum=0.2)\n",
    "model.compile(loss='hinge', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QprAETU6tEmU",
    "outputId": "9bff1a57-724d-4f7a-b26a-ae5f213ebc59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 1s 23ms/step - loss: 0.8700 - accuracy: 0.6275 - val_loss: 0.9974 - val_accuracy: 0.5025\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.8641 - accuracy: 0.6275 - val_loss: 0.9973 - val_accuracy: 0.5025\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.8570 - accuracy: 0.6275 - val_loss: 0.9972 - val_accuracy: 0.5025\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.8496 - accuracy: 0.6275 - val_loss: 0.9971 - val_accuracy: 0.5025\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.8462 - accuracy: 0.6275 - val_loss: 0.9970 - val_accuracy: 0.5025\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.8410 - accuracy: 0.6275 - val_loss: 0.9969 - val_accuracy: 0.5025\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.8346 - accuracy: 0.6275 - val_loss: 0.9968 - val_accuracy: 0.5025\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.8299 - accuracy: 0.6275 - val_loss: 0.9967 - val_accuracy: 0.5025\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.8242 - accuracy: 0.6275 - val_loss: 0.9966 - val_accuracy: 0.5025\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.8200 - accuracy: 0.6275 - val_loss: 0.9965 - val_accuracy: 0.5025\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.8152 - accuracy: 0.6275 - val_loss: 0.9964 - val_accuracy: 0.5025\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.8116 - accuracy: 0.6275 - val_loss: 0.9963 - val_accuracy: 0.5025\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.8083 - accuracy: 0.6275 - val_loss: 0.9963 - val_accuracy: 0.5025\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.8053 - accuracy: 0.6275 - val_loss: 0.9962 - val_accuracy: 0.5025\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.8015 - accuracy: 0.6275 - val_loss: 0.9961 - val_accuracy: 0.5025\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7981 - accuracy: 0.6275 - val_loss: 0.9961 - val_accuracy: 0.5025\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7951 - accuracy: 0.6275 - val_loss: 0.9960 - val_accuracy: 0.5025\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7934 - accuracy: 0.6275 - val_loss: 0.9960 - val_accuracy: 0.5025\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7920 - accuracy: 0.6275 - val_loss: 0.9960 - val_accuracy: 0.5025\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7900 - accuracy: 0.6275 - val_loss: 0.9959 - val_accuracy: 0.5025\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7881 - accuracy: 0.6275 - val_loss: 0.9959 - val_accuracy: 0.5025\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7864 - accuracy: 0.6275 - val_loss: 0.9959 - val_accuracy: 0.5025\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7848 - accuracy: 0.6275 - val_loss: 0.9958 - val_accuracy: 0.5025\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7832 - accuracy: 0.6275 - val_loss: 0.9958 - val_accuracy: 0.5025\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7819 - accuracy: 0.6275 - val_loss: 0.9958 - val_accuracy: 0.5025\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7808 - accuracy: 0.6275 - val_loss: 0.9958 - val_accuracy: 0.5025\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7796 - accuracy: 0.6275 - val_loss: 0.9957 - val_accuracy: 0.5025\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7784 - accuracy: 0.6275 - val_loss: 0.9957 - val_accuracy: 0.5025\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.7769 - accuracy: 0.6275 - val_loss: 0.9957 - val_accuracy: 0.5025\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7759 - accuracy: 0.6275 - val_loss: 0.9957 - val_accuracy: 0.5025\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7746 - accuracy: 0.6275 - val_loss: 0.9957 - val_accuracy: 0.5025\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7736 - accuracy: 0.6275 - val_loss: 0.9956 - val_accuracy: 0.5025\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7724 - accuracy: 0.6275 - val_loss: 0.9956 - val_accuracy: 0.5025\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7716 - accuracy: 0.6275 - val_loss: 0.9956 - val_accuracy: 0.5025\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7706 - accuracy: 0.6275 - val_loss: 0.9956 - val_accuracy: 0.5025\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7697 - accuracy: 0.6275 - val_loss: 0.9956 - val_accuracy: 0.5025\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7690 - accuracy: 0.6275 - val_loss: 0.9956 - val_accuracy: 0.5025\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7686 - accuracy: 0.6275 - val_loss: 0.9955 - val_accuracy: 0.5025\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7679 - accuracy: 0.6275 - val_loss: 0.9955 - val_accuracy: 0.5025\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7671 - accuracy: 0.6275 - val_loss: 0.9955 - val_accuracy: 0.5025\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.7666 - accuracy: 0.6275 - val_loss: 0.9955 - val_accuracy: 0.5025\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7661 - accuracy: 0.6275 - val_loss: 0.9955 - val_accuracy: 0.5025\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7655 - accuracy: 0.6275 - val_loss: 0.9955 - val_accuracy: 0.5025\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.7651 - accuracy: 0.6275 - val_loss: 0.9955 - val_accuracy: 0.5025\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.7644 - accuracy: 0.6275 - val_loss: 0.9955 - val_accuracy: 0.5025\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7640 - accuracy: 0.6275 - val_loss: 0.9955 - val_accuracy: 0.5025\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7636 - accuracy: 0.6275 - val_loss: 0.9954 - val_accuracy: 0.5025\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7631 - accuracy: 0.6275 - val_loss: 0.9954 - val_accuracy: 0.5025\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7627 - accuracy: 0.6275 - val_loss: 0.9954 - val_accuracy: 0.5025\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7623 - accuracy: 0.6275 - val_loss: 0.9954 - val_accuracy: 0.5025\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7619 - accuracy: 0.6275 - val_loss: 0.9954 - val_accuracy: 0.5025\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7616 - accuracy: 0.6275 - val_loss: 0.9954 - val_accuracy: 0.5025\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7613 - accuracy: 0.6275 - val_loss: 0.9954 - val_accuracy: 0.5025\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7609 - accuracy: 0.6275 - val_loss: 0.9954 - val_accuracy: 0.5025\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7606 - accuracy: 0.6275 - val_loss: 0.9954 - val_accuracy: 0.5025\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7603 - accuracy: 0.6275 - val_loss: 0.9954 - val_accuracy: 0.5025\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.7601 - accuracy: 0.6275 - val_loss: 0.9954 - val_accuracy: 0.5025\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7598 - accuracy: 0.6275 - val_loss: 0.9954 - val_accuracy: 0.5025\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7596 - accuracy: 0.6275 - val_loss: 0.9954 - val_accuracy: 0.5025\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.7594 - accuracy: 0.6275 - val_loss: 0.9954 - val_accuracy: 0.5025\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.7591 - accuracy: 0.6275 - val_loss: 0.9954 - val_accuracy: 0.5025\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7589 - accuracy: 0.6275 - val_loss: 0.9954 - val_accuracy: 0.5025\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7586 - accuracy: 0.6275 - val_loss: 0.9954 - val_accuracy: 0.5025\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7583 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7581 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7579 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7577 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7575 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7573 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7571 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7569 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7568 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7565 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7564 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7562 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7561 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7559 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7557 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.7555 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7553 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.7552 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.7551 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7549 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7548 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7547 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.7546 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7544 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7543 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7542 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7541 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7539 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.7538 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7538 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7537 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7535 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7534 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7534 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7533 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7532 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7531 - accuracy: 0.6275 - val_loss: 0.9953 - val_accuracy: 0.5025\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, validation_data=(X_test,y_test),epochs=100,batch_size=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLWSGToEtaVH",
    "outputId": "87211ec6-51ae-4d51-d97e-07a8ef5b9119"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.627, Valid: 0.502\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(X_train,y_train, verbose=0)\n",
    "_, valid_acc = model.evaluate(X_test,y_test, verbose=0)\n",
    "print('Train: %.3f, Valid: %.3f' % (train_acc, valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w541BIe38vbR",
    "outputId": "c9183534-c1b6-40ee-c105-abde7d41c6a3"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.656863 using {'batch_size': 510, 'epochs': 400}\n",
      "0.598039 (0.084337) with: {'batch_size': 1, 'epochs': 100}\n",
      "0.549020 (0.060435) with: {'batch_size': 1, 'epochs': 200}\n",
      "0.598039 (0.084337) with: {'batch_size': 1, 'epochs': 300}\n",
      "0.578431 (0.132262) with: {'batch_size': 1, 'epochs': 400}\n",
      "0.588235 (0.063537) with: {'batch_size': 1, 'epochs': 500}\n",
      "0.598039 (0.077196) with: {'batch_size': 1, 'epochs': 600}\n",
      "0.588235 (0.063537) with: {'batch_size': 1, 'epochs': 700}\n",
      "0.588235 (0.024015) with: {'batch_size': 1, 'epochs': 800}\n",
      "0.627451 (0.060435) with: {'batch_size': 1, 'epochs': 900}\n",
      "0.588235 (0.063537) with: {'batch_size': 1, 'epochs': 1000}\n",
      "0.647059 (0.072044) with: {'batch_size': 32, 'epochs': 100}\n",
      "0.627451 (0.027730) with: {'batch_size': 32, 'epochs': 200}\n",
      "0.617647 (0.048029) with: {'batch_size': 32, 'epochs': 300}\n",
      "0.578431 (0.013865) with: {'batch_size': 32, 'epochs': 400}\n",
      "0.617647 (0.024015) with: {'batch_size': 32, 'epochs': 500}\n",
      "0.578431 (0.027730) with: {'batch_size': 32, 'epochs': 600}\n",
      "0.588235 (0.063537) with: {'batch_size': 32, 'epochs': 700}\n",
      "0.647059 (0.063537) with: {'batch_size': 32, 'epochs': 800}\n",
      "0.607843 (0.073366) with: {'batch_size': 32, 'epochs': 900}\n",
      "0.627451 (0.055459) with: {'batch_size': 32, 'epochs': 1000}\n",
      "0.627451 (0.049990) with: {'batch_size': 128, 'epochs': 100}\n",
      "0.637255 (0.060435) with: {'batch_size': 128, 'epochs': 200}\n",
      "0.647059 (0.072044) with: {'batch_size': 128, 'epochs': 300}\n",
      "0.637255 (0.060435) with: {'batch_size': 128, 'epochs': 400}\n",
      "0.656863 (0.027730) with: {'batch_size': 128, 'epochs': 500}\n",
      "0.637255 (0.036683) with: {'batch_size': 128, 'epochs': 600}\n",
      "0.647059 (0.041595) with: {'batch_size': 128, 'epochs': 700}\n",
      "0.637255 (0.013865) with: {'batch_size': 128, 'epochs': 800}\n",
      "0.588235 (0.024015) with: {'batch_size': 128, 'epochs': 900}\n",
      "0.627451 (0.036683) with: {'batch_size': 128, 'epochs': 1000}\n",
      "0.627451 (0.049990) with: {'batch_size': 256, 'epochs': 100}\n",
      "0.627451 (0.049990) with: {'batch_size': 256, 'epochs': 200}\n",
      "0.647059 (0.072044) with: {'batch_size': 256, 'epochs': 300}\n",
      "0.647059 (0.024015) with: {'batch_size': 256, 'epochs': 400}\n",
      "0.647059 (0.063537) with: {'batch_size': 256, 'epochs': 500}\n",
      "0.637255 (0.055459) with: {'batch_size': 256, 'epochs': 600}\n",
      "0.627451 (0.036683) with: {'batch_size': 256, 'epochs': 700}\n",
      "0.617647 (0.024015) with: {'batch_size': 256, 'epochs': 800}\n",
      "0.607843 (0.036683) with: {'batch_size': 256, 'epochs': 900}\n",
      "0.617647 (0.024015) with: {'batch_size': 256, 'epochs': 1000}\n",
      "0.627451 (0.049990) with: {'batch_size': 510, 'epochs': 100}\n",
      "0.627451 (0.049990) with: {'batch_size': 510, 'epochs': 200}\n",
      "0.637255 (0.060435) with: {'batch_size': 510, 'epochs': 300}\n",
      "0.656863 (0.049990) with: {'batch_size': 510, 'epochs': 400}\n",
      "0.656863 (0.027730) with: {'batch_size': 510, 'epochs': 500}\n",
      "0.637255 (0.036683) with: {'batch_size': 510, 'epochs': 600}\n",
      "0.647059 (0.024015) with: {'batch_size': 510, 'epochs': 700}\n",
      "0.627451 (0.036683) with: {'batch_size': 510, 'epochs': 800}\n",
      "0.627451 (0.060435) with: {'batch_size': 510, 'epochs': 900}\n",
      "0.588235 (0.024015) with: {'batch_size': 510, 'epochs': 1000}\n"
     ]
    }
   ],
   "source": [
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(10, input_dim=21, kernel_initializer='uniform', activation='softmax', kernel_constraint=maxnorm(4)))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    " \n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=SGD(learning_rate=0.1, momentum=0.2), metrics=['accuracy'])\n",
    "\treturn model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "# define the grid search parameters\n",
    "epochs = [100,200,300,400,500,600,700,800,900,1000]\n",
    "batch_size = [1,32,128,256,510]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train,y_train, validation_data=(X_test,y_test))\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Activation,Epoch, & Batch Size",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
